{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZ94Ro0oD-Hr",
    "outputId": "7cc68320-d5d1-4c16-a30d-d81d6eedc99b"
   },
   "outputs": [],
   "source": [
    "import os, json, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohTWPtsrmo4z",
    "outputId": "8a23330d-73e4-483c-df7d-261adaab4e7f"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oimzYeOnmit1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population size: 43148\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Book_1_50.csv')\n",
    "# Check the population size (number of rows) in your DataFrame\n",
    "print(\"Population size:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Qp3_pIQKIcTn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population size: 43131\n",
      "5.0    34452\n",
      "4.0     5514\n",
      "3.0     1861\n",
      "2.0      692\n",
      "1.0      612\n",
      "Name: overall, dtype: int64\n",
      "Population size: 43131\n"
     ]
    }
   ],
   "source": [
    "# drop any rows w/ missing values\n",
    "df = df.dropna(subset=[\"reviewText\"])\n",
    "print(\"Population size:\", len(df))\n",
    "#discover the actual counts\n",
    "print(df.overall.value_counts())\n",
    "\n",
    "print(\"Population size:\", len(df))\n",
    "\n",
    "# set sample size to labels w/ minimum count\n",
    "sample_size = 612\n",
    "# Collect samples for each class in a list\n",
    "samples_list = [df[df.overall == label].sample(n=sample_size, random_state=1) for label in df.overall.unique()]\n",
    "\n",
    "# Concatenate all the samples into one DataFrame\n",
    "df_equal_overall = pd.concat(samples_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UxmFNVnZK4Lm"
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def ReviewProcessing(df):\n",
    "  # remove non alphanumeric\n",
    "  df['review_cleaned'] = df.reviewText.str.replace('[^a-zA-Z0-9 ]', '')\n",
    "  # lowercase\n",
    "  df.review_cleaned = df.review_cleaned.str.lower()\n",
    "  # split into list\n",
    "  df.review_cleaned = df.review_cleaned.str.split(' ')\n",
    "  # remove stopwords\n",
    "  df.review_cleaned = df.review_cleaned.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qBSJh6LDK5nC"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def get_lemmatize(sent):\n",
    "  return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sent)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XDHw55bpK8if",
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_data = ReviewProcessing(df_equal_overall)\n",
    "clean_data.review_cleaned = clean_data.review_cleaned.apply(' '.join)\n",
    "clean_data['review_cleaned_lemmatized'] = clean_data.review_cleaned.apply(get_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QgsSkSBrabb_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vectorize', CountVectorizer(ngram_range=(1, 2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PA2XdDtOchmE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier()),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yGQyQ3n4ckQd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(max_iter=500)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TCWm1ga7cn7D"
   },
   "outputs": [],
   "source": [
    "x = clean_data['review_cleaned_lemmatized']\n",
    "y = clean_data['overall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    test_size=0.2, stratify=y, random_state = 44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5aoew6vcq2t",
    "outputId": "739a45d6-d26b-43f2-ff39-d006684db53f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4411764705882353\n",
      "[[60 42  8  9  3]\n",
      " [20 64 14 11 13]\n",
      " [10 47 38 20  7]\n",
      " [ 6 29 12 41 35]\n",
      " [ 4 18 11 23 67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.49      0.54       122\n",
      "         2.0       0.32      0.52      0.40       122\n",
      "         3.0       0.46      0.31      0.37       122\n",
      "         4.0       0.39      0.33      0.36       123\n",
      "         5.0       0.54      0.54      0.54       123\n",
      "\n",
      "    accuracy                           0.44       612\n",
      "   macro avg       0.46      0.44      0.44       612\n",
      "weighted avg       0.46      0.44      0.44       612\n",
      "\n",
      "0.43300653594771243\n",
      "[[66 20 13 12 11]\n",
      " [29 43 18 19 13]\n",
      " [11 27 39 29 16]\n",
      " [ 6 10 23 45 39]\n",
      " [ 6  4 16 25 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.54      0.55       122\n",
      "         2.0       0.41      0.35      0.38       122\n",
      "         3.0       0.36      0.32      0.34       122\n",
      "         4.0       0.35      0.37      0.36       123\n",
      "         5.0       0.48      0.59      0.53       123\n",
      "\n",
      "    accuracy                           0.43       612\n",
      "   macro avg       0.43      0.43      0.43       612\n",
      "weighted avg       0.43      0.43      0.43       612\n",
      "\n",
      "0.4673202614379085\n",
      "[[73 23  9 11  6]\n",
      " [33 44 17 14 14]\n",
      " [11 38 41 23  9]\n",
      " [ 5 18 11 52 37]\n",
      " [ 8  9 13 17 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.60      0.58       122\n",
      "         2.0       0.33      0.36      0.35       122\n",
      "         3.0       0.45      0.34      0.38       122\n",
      "         4.0       0.44      0.42      0.43       123\n",
      "         5.0       0.54      0.62      0.57       123\n",
      "\n",
      "    accuracy                           0.47       612\n",
      "   macro avg       0.47      0.47      0.46       612\n",
      "weighted avg       0.47      0.47      0.46       612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_nb))\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_sgd))\n",
    "print(confusion_matrix(y_test, y_pred_sgd))\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "_h5I-OLqcu7A",
    "outputId": "28edec27-3ae3-4b7c-8b06-0e21da81cbc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  45 | elapsed:    5.8s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 2), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('tfidf',\n",
      "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
      "                                  sublinear_tf=False, use_idf=True)),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=500,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='saga', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "0.4489019656942531\n",
      "[[73 23  9 11  6]\n",
      " [31 46 17 14 14]\n",
      " [11 38 41 23  9]\n",
      " [ 5 18 11 52 37]\n",
      " [ 8  9 13 17 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.60      0.58       122\n",
      "         2.0       0.34      0.38      0.36       122\n",
      "         3.0       0.45      0.34      0.38       122\n",
      "         4.0       0.44      0.42      0.43       123\n",
      "         5.0       0.54      0.62      0.57       123\n",
      "\n",
      "    accuracy                           0.47       612\n",
      "   macro avg       0.47      0.47      0.47       612\n",
      "weighted avg       0.47      0.47      0.47       612\n",
      "\n",
      "0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid=[{'clf__solver': ['lbfgs', 'sag', 'saga'],\n",
    "       'clf__C': [0.01, 0.1, 1]}]\n",
    "lr = GridSearchCV(logreg, param_grid = grid, cv = 5, scoring='accuracy', verbose = 1, n_jobs = -1)\n",
    "best_model = lr.fit(X_train, y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print(best_model.best_score_)\n",
    "\n",
    "y_pred_grid = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_grid))\n",
    "print(classification_report(y_test, y_pred_grid))\n",
    "print(accuracy_score(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
